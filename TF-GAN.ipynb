{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5,5), strides=(1,1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1, (5,5), strides=(2,2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2bce0fdcb88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5,5), strides=(2,2), padding='same', input_shape=[28,28,1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00175923]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        \n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d152560ca122>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-802af7bf198a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m       \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Produce images for the GIF as we go\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
